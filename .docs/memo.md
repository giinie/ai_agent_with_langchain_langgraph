# 랭체인 & 랭그래프로 AI 에이전트 개발하기 - 서지영

## 목차

1. LLM 트렌드 이해하기
   1. LLM의 등장과 AI 생태계의 변화
      1. LLM의 탄생
      2. LLM의 발전: 멀티모달 LLM
      3. LLM의 발전: 모델 규모의 확장
      4. LLM의 발전: 오픈소스와 커뮤니티 역할의 확대
   2. LLM의 진화와 AI 에이전트 등장
      1. o1의 등장
      2. AI 에이전트의 등장
2. AI 에이전트 이해하기
   1. AI 에이전트의 개념
      1. AI 에이전트란?
      2. LLM, RAG, AI 에이전트 비교
   2. AI 에이전트 구성 및 동작 방식
      1. AI 에이전트 구성 요소
      2. AI 에이전트 동작 방식
      3. 에이전트 유형
   3. AI 에이전트 디자인 패턴
      1. 반응 패턴
      2. 계획 패턴
      3. 도구 사용 패턴
      4. 멀티에이전트 패턴
      5. CoT 프롬프팅 패턴
   4. AI 에이전트 프레임워크
      1. AutoGEN
      2. LangChain
      3. LangGraph
      4. CrewAI
      5. LlamaIndex
      6. AutoGPT
3. AI 에이전트 활용하기
   1. AI 에이전트를 사용하기 위한 준비
      1. 코랩 환경 구성
      2. API 키 발급
   2. AI 에이전트 구현하기
      1. LangChain Agent
      2. AutoGPT
      3. AutoGEN
      4. LlamaIndex
      5. CrewAI
      6. LangGraph 활용하기
   3. LangSmith를 이용한 에이전트 디버깅 및 평가
4. M365 코파일럿 에이전트
   1. M365 코파일럿과 M365 코파일럿 에이전트
   2. M365 코파일럿 에이전트 vs. AI 에이전트

---

## 1. LLM 트렌드 이해하기

### 1. LLM의 등장과 AI 생태계의 변화

#### 1. LLM의 탄생

1. 트랜스포머(Transformer) 모델의 등장 (2017)
   - Attention Mechanism: 데이터에서 중요한 부분에 더 집중할 수 있도록 하는 기술
     - 입력 데이터 분석 > 중요도 계산 > 가중치 부여
     - 자연어 처리(Natural Language Processing, NLP), 컴퓨터 비전(Computer Vision) 분야에서 활용
2. GPT 시리즈의 발전
   - GPT-1(2018): 트랜스포머 구조를 활용한 최초의 언어 모델
   - GPT-2(2019): 더 많은 데이터를 학습하고, 더 정교한 텍스트를 생성
   - GPT-3(2020): 1,750억 개의 파라미터를 가진 모델, 자연스러운 글쓰기와 대화 능력 선보임
   - ChatGPT(2022): GPT-3 기반, 대화에 최적화된 형태
   - GPT-4(2023): 더욱 많은 파라미터와 Multimodal 기능을 갖춘 모델
   - GPT-4o(2024): 'o'는 '모든', '전체의'를 뜻하는 Omni의 약자. 즉 이미지, 음성 등 '모든' 형태의 데이터를 이해하고 처리
3. 경쟁과 협업
   - BERT(Google), LLaMA(Large Language Model Meta AI, Meta)

#### 2. LLM의 발전: 멀티모달(Multimodal) LLM

1. 음성과 텍스트의 통합
   - 음성을 텍스트와 연결하여 두 가지를 함께 처리: 음성-텍스트 상호 변환
   - OpenAI의 Whisper API 같은 음성 인식 모델과 결합하여 사용
2. 이미지와 텍스트의 통합
   - 이미지를 분석하여 객체, 장면, 감정 등을 이해
3. 기타 데이터와의 융합
   - IoT 기기, 센서 데이터 등 다양한 소스에서 정보를 받아 통합적으로 처리 가능

#### 3. LLM의 발전: 모델 규모의 확장

- 파라미터 개수와 성능의 상관관계
  - parameter: AI가 학습을 통해 얻은 일종의 규칙, 데이터 처리 및 결과 예측에 사용하는 핵심 구성 요소

#### 4. LLM의 발전: 오픈소스와 커뮤니티 역할의 확대

- 접근성 향상: 누구라도 접근하여 사용 가능
- 협업과 지식 공유: github, hugging face 같은 플랫폼에서 커뮤니티가 모델 개선에 참여
- 스타트업과 중소기업에 기회 제공
- AI 민주화: 커뮤니티는 LLM에 대한 접근성을 높이고, 더 많은 사람들이 LLM을 학습하고 활용할 수 있도록 함

### 2. LLM의 진화와 AI 에이전트 등장

#### 1. o1의 등장

1. GPT-4o와 o1의 비교
   - o1: OpenAI가 2024년 9월에 공개한 모델, 복잡한 추론 능력을 강화
   - 추론(Reasoning): 응답 생성 전에 '사고의 흐름(chain of thought)'를 형성하여 복잡한 문제를 단계별로 해결
   - 사고의 흐름을 보여줌으로써 블랙박스 문제 해결, LLM 내부 작동 방식에 대한 투명성 향상
2. 시나리오로 알아보는 o1

#### 2. AI 에이전트의 등장

---

## 2. AI 에이전트 이해하기
### 1. AI 에이전트의 개념
#### 1. AI 에이전트란?
#### 2. LLM, RAG, AI 에이전트 비교
### 2. AI 에이전트 구성 및 동작 방식
#### 1. AI 에이전트 구성 요소
#### 2. AI 에이전트 동작 방식
#### 3. 에이전트 유형
### 3. AI 에이전트 디자인 패턴
#### 1. 반응 패턴
#### 2. 계획 패턴
#### 3. 도구 사용 패턴
#### 4. 멀티에이전트 패턴
#### 5. CoT 프롬프팅 패턴
### 4. AI 에이전트 프레임워크
#### 1. AutoGEN
#### 2. LangChain
#### 3. LangGraph
#### 4. CrewAI
#### 5. LlamaIndex
#### 6. AutoGPT

---

## 3. AI 에이전트 활용하기
### 1. AI 에이전트를 사용하기 위한 준비
#### 1. 코랩 환경 구성
#### 2. API 키 발급
### 2. AI 에이전트 구현하기
#### 1. LangChain Agent
#### 2. AutoGPT
#### 3. AutoGEN
#### 4. LlamaIndex
#### 5. CrewAI
#### 6. LangGraph 활용하기
### 3. LangSmith를 이용한 에이전트 디버깅 및 평가

---

## 4. M365 코파일럿 에이전트
### 1. M365 코파일럿과 M365 코파일럿 에이전트
### 2. M365 코파일럿 에이전트 vs. AI 에이전트

---

# 랭체인으로 LLM 기반의 AI 서비스 개발하기 - 서지영

## 목차

1. LLM 훑어보기
2. LLM 활용하기
3. RAG 훑어보기
4. 랭체인 익숙해지기
5. 랭체인으로 RAG 구현하기
    1. LLM을 이용한 간단한 챗봇
    2. 랭체인과 챗GPT로 RAG 기반의 챗봇
    3. PDF를 요약해주는 웹사이트
    4. PDF 파일에 대한 독립형 질문을 하는 챗봇
    5. 대화형 챗봇
    6. 번역 서비스
    7. 메일 작성기
    8. LLM을 이용해서 CSV 파일 분석
6. LLM을 이용한 서비스 알아보기

---

## 1. LLM 훑어보기

### 1. 언어 모델(Language Model)

- 통계적 언어 모델
- 신경망 언어 모델
- 트랜스포머

### 2. LLM 생태계

- Infrastructure Layer
- Application Layer

### 3. LLM, GAI, SLM

- Generative AI
- prompt, completion
- Small Language Model

### 4. LLM 생성 과정

1. **데이터 수집 및 준비**
    - 데이터 수집 > 데이터 정제 > 데이터 전처리 > 데이터 형식 변경
    - 데이터 전처리 : 토큰화(tokenization), 정규화
2. **모델 설계**
    - 신경망 아키텍처(주로 트랜스포머) 구축, hyperparameter(계층수, 학습률, 배치 크기...) 설정
3. **모델 학습**
    - 모델링 : 주어진 데이터를 기반으로 일반화된 패턴이나 규칙을 만드는 것.
4. **평가 및 검증**
    - 정확도(accuracy)
    - 정밀도(precision)
    - 재현율(recall)
    - F1 점수(F1 score)
    - ROC-curve/AUC
5. **배포 및 유지 보수**

### 5. LLM 생성 후 추가 고려 사항

- 윤리적 고려 및 보정 : 책임감 있는 AI(Responsible AI)
- 지속적 모니터링

---

## 2. LLM 활용하기

### 1. LLM 활용 방법

1. 파인튜닝(Fine-Tuning)
    - 전이 학습(Transfer Learning)의 한 형태로 모델을 특정 분야나 작업에 최적화시키기 위해 추가적인 학습을 시키는 과정
2. RAG(Retrieval-Augmented Generation)
    - 자연어 처리 분야에서 사용되는 기술
    - 정보 검색과 생성을 결합한 인공지능 모델
    - 복잡하고 정보가 필요한 질문에 답변하기 위해 설계
    - 정보 검색 단계
        - 질문: 사용자로부터 질문 입력
        - 쿼리(문서 검색): 모델은 질문과 관련된 문서나 정보 검색(문서 데이터베이스, 콘텐츠 저장소)
        - 정보 검색 결과: 검색 결과 중 가장 관련성 높은 문서와 사용자의 질문을 결합하여 LLM에 전달
    - 텍스트 생성 단계
        - 정보 전달: 모델에 전달(사용자의 질문 + 정보 검색 결과)
        - 텍스트 생성: 전달받은 정보를 바탕으로 질문에 대한 답변 생성
3. 퓨샷 러닝(Few Shot Learning)
    - 매우 적은 양의 데이터로 학습하는 능력
    - 기존에 학습한 지식을 바탕으로 매우 제한된 예시로부터 새로운 작업에 빠르게 적용
    - Zero Shot Learning, One Shot Learning
    - 특정 작업이나 분야에서 충분한 양의 데이터를 확보하기 어려울 때 유용

### 2. LLM 활용 시 주의 사항

- 정보 필터링: 유해 정보, 개인 정보 등 필터링
- 법적인 규제
- Hallucination
- 보안

### 3. LLM의 한계

- 편향과 공정성
- 투명성
- 데이터 의존성
- 정보의 일반화
- 오류 가능성
- 개인 정보 보호
- 새로운 정보의 결여
- 기업 내 데이터 미활용

---

## 3. RAG 훑어보기

### 1. RAG 개념

- RAG(Retrieval-Augmented Generation)
- LLM이 텍스트를 생성할 때 관련 정보를 찾아보고(retrieval), 그 정보를 활용하여 새로운 텍스트를 만드는(generation) 기술

### 2. RAG 구현 과정

1. 정보 검색
    1) 질문 입력
    2) 검색
    3) 유사도 검색
        - keyword search, semantic search
    4) 랭킹 처리: 모델이 생성할 텍스트와 가장 관련이 높은 정보를 선택하는 과정
        - 유사도 계산
        - 문맥과 의도 파악
        - 랭킹 산출

2. 정보 검색 (심화)
    - 벡터와 유사도
    - 유사도 계산
        - 코사인 유사도: 두 벡터 간의 각도를 계산하여 그 유사성을 측정하는 방법
        - 유클리드 유사도: 두 점 사이의 직선 거리
    - 검색 결과 랭킹 처리
        - 페이지랭크(PageRank)
        - TF-IDF(Term Frequency-Inverse Document Frequency)
        - 클릭률(Click-Through Rate, CTR)

3. 텍스트 생성
    1) (검색 엔진의 경우) 결과 반환
    2) (LLM의 경우) 텍스트 생성

### 3. RAG 구현 시 필요한 것

1. 데이터
    - 시맨틱 검색
    - 벡터 검색
        - 임베딩 모델
            - Word2Vec: 단어를 컴퓨터가 이해할 수 있는 숫자인 벡터로 변환하는 모델
            - OpenAI 임베딩 모델: 한국어 지원은 물론, RAG 정보 검색과 랭크 처리도 우월

2. 벡터 데이터베이스
    - 벡터를 저장하는 저장소
    - 데이터의 정확한 값 대신 데이터 간의 '유사성'을 바탕으로 검색
    - Pinecone: 머신러닝과 인공지능 애플리케이션을 위해 설계
    - Milvus: 클라우드에서 사용 가능한 오픈 소스 벡터 데이터베이스. 다양한 유형의 데이터를 다루도록 최적화.
    - Qdrant: 고차원 데이터 벡터를 효율적으로 저장/검색
    - Chroma: LLM을 위해 설계. 텍스트 데이터와 언어 모델에 특화.
    - Elasticsearch: 강력한 검색과 데이터 분석 기능을 제공하는 검색 엔진.
    - FAISS: Facebook AI Research(FAIR)에서 개발한 라이브러리. 벡터 인덱스 기능 제공.

   | DB            | 특징                                                      | 장점                                       | 단점                                                                                    |
   |---------------|---------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------|
   | Pinecone      | - 간단한 API<br/> - 빠른 검색 성능                               | - 클라우드 기반으로 쉬운 확장성<br/> - 높은 가용성 및 보안성   | - 제어에 제한이 있을 수 있음                                                                     |
   | Milvus        | - Open Source<br/> - 고성능<br/> - 광범위한 AI 애플리케이션 지원       | - 무료로 사용 가능<br/> - 높은 수준의 제어가 가능         | - 관리와 유지보수 필요                                                                         |
   | Qdrant        | - Open Source<br/> - 고성능<br/> - 유연한 데이터 모델링 및 고급 필터링 기능 | - 벡터 및 스칼라 데이터 모두 지원<br/> - 복잡한 검색 쿼리 가능 | - 커뮤니티 지원이 밀버스나 엘라스틱서치에 비해 제한적                                                        |
   | Chroma        | - LLM을 위한 벡터 데이터베이스                                     | - 텍스트 데이터와 언어 모델에 특화된 기능을 제공             | - 이미지나 오디오 데이터 같은 다른 유형의 벡터 데이터 처리에는 덜 최적화되어 있음                                       |
   | Elasticsearch | - 널리 사용되는 검색 엔진<br/> - 벡터 검색과 전통적인 텍스트 검색을 모두 지원        | - 다양한 플러그인 및 통합 옵션                       | - 벡터 검색에 대해 다른 전문 벡터 데이터베이스만큼 강력하지 않을 수 있음<br/> - 데이터 사이즈가 커지면 그에 따라 리소스 사용량이 높을 수 있음 |
   | FAISS         | - Open Source<br/> - 고성능                                | - 무료로 사용 가능<br/> - GPU와 결합하여 빠른 검색 기능 제공 | - 인덱스에 대한 사전 지식이 필요                                                                   |

3. Framework(LangChain)
   - 언어 모델을 위한 프레임워크
   - LLM을 활용하여 손쉽게 서비스를 개발할 수 있는 도구

---

## 4. 랭체인 익숙해지기

- LLM을 활용하기 위해 필요한 모듈의 모음이자 조합

### 1. 랭체인 훑어보기

- 임베딩, 유사도 검색, 랭킹 처리
- LLM과 외부 도구를 결합

### 2. 랭체인을 사용하기 위한 환경 구성

- Python, JavaScript 지원

### 3. 랭체인 주요 모듈

1. 모델 I/O(Model I/O): 언어 모델과 상호 작용을 위한 모듈
   - 프롬프트
   - 언어 모델: LLM API 호출
   - 출력 파서(Output Parsers)

2. 데이터 연결: 일반적인 데이터 분석 환경에서의 ETL(Extract, Transform, Load)에 해당
   - 문서 가져오기(document loaders): 다양한 출처에서 문서를 가져오는 것
   - 문서 변환(document transformers): chunk 분할, 결합, 필터링 등
   - 문서 임베딩(embedding model): vector 변환
   - 벡터 저장소(vector stores): 벡터 저장/관리/검색
   - 검색기(retrievers): 언어 모델과 결합할 관련 문서를 가져오기 위한 것으로 정보 검색을 위한 역할

3. 체인
   - 여러 구성 요소를 조합해서 하나의 파이프라인을 구성해주는 역할

4. 메모리
   - 모든 대화 유지
   - 최근 k개의 대화 유지
   - 대화를 요약해서 유지

5. 에이전트/툴
   - 에이전트: LLM을 이용해서 어떤 작업을 어떤 순서로 수행할지 결정하는 역할
   - 툴: 특정 작업을 수행하기 위한 도구로 LLM 이외의 다른 리소스를 의미

---

## 6. LLM을 이용한 서비스 알아보기

### 1. 콜센터

- 스크립트 생성: 추가 교육 및 신규 상담원 교육 대신 LLM을 이용해서 스크립트 생성
- 상담 업무를 모두 LLM으로 대체
- 챗GPT로 상답 업무를 도와주는 솔루션을 가지고 있는 기업: Centrical, AICC 등

### 2. 상품추천

- 시맨틱 검색

### 3. 보험 언더라이팅(Insurance Underwriting)

- 보험 회사가 사용자의 보험 가입 신청서를 검토하고 보험 계약을 체결할 때 어떤 조건과 가격을 제공해야 하는지 결정하는 과정
- 보험 회사가 감수해야 할 리스크를 정확하게 평가하고 관리하기 위해 반드시 필요한 과정
- 교보생명이 자연어 처리를 기반으로 하는 모델을 개발(심사용 AI 모델, 사전 심사 결과, 질병 여부, 최근 3년 내 보험금 지급 내역 등 함께 참조)

### 4. 코드 생성 및 리뷰

### 5. 문장 생성, M365 코파일럿

- 오피스가 포함된 M365 제품
- 마이크로소프트 그래프(검색 엔진)
- 거대 언어 모델(GPT-4)